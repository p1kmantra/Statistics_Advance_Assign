{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Q.1.Explain the properties of the F-distribution."
      ],
      "metadata": {
        "id": "WSwB4uYs7hE2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "The F-distribution is crucial in statistics, especially when comparing variances across different groups. Here are its main properties:\n",
        "\n",
        "(a).Range: The F-distribution only takes positive values. It starts at 0 and extends to infinity.\n",
        "\n",
        "(b).Shape: It's right-skewed (positively skewed), becoming less skewed as the degrees of freedom increase.\n",
        "\n",
        "(c).Degrees of Freedom: It has two sets of degrees of freedom, one for the numerator (df1) and one for the denominator (df2).\n",
        "\n",
        "(d).Mean: The mean of the F-distribution is approximately\n",
        "ùëë\n",
        "ùëì\n",
        "2/\n",
        "ùëë\n",
        "ùëì\n",
        "2\n",
        "‚àí\n",
        "2\n",
        " for\n",
        "ùëë\n",
        "ùëì\n",
        "2> 2\n",
        ".\n",
        "\n",
        "(e). Variance: The variance is\n",
        "2\n",
        "√ó\n",
        "(\n",
        "ùëë\n",
        "ùëì\n",
        "2\n",
        "2\n",
        ")\n",
        "√ó\n",
        "(\n",
        "ùëë\n",
        "ùëì\n",
        "1\n",
        "+\n",
        "ùëë\n",
        "ùëì\n",
        "2\n",
        "‚àí\n",
        "2\n",
        ")\n",
        "ùëë\n",
        "ùëì\n",
        "1\n",
        "√ó\n",
        "(\n",
        "ùëë\n",
        "ùëì\n",
        "2\n",
        "‚àí\n",
        "2\n",
        ")\n",
        "2\n",
        "√ó\n",
        "(\n",
        "ùëë\n",
        "ùëì\n",
        "2\n",
        "‚àí\n",
        "4\n",
        ")\n",
        " for\n",
        "ùëë\n",
        "ùëì\n",
        "2>4\n",
        ".\n",
        "Applications:\n",
        "\n",
        "ANOVA (Analysis of Variance): The F-distribution is used to compare variances and test hypotheses about population means.\n",
        "\n",
        "Regression Analysis: It helps in determining the overall significance of a regression model.\n",
        "\n",
        "The F-distribution's properties make it a powerful tool for statistical hypothesis testing and comparing datasets."
      ],
      "metadata": {
        "id": "KiUUEaKR9Fwz"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pykVP8XK-hsS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.2.In which type of Statisical test is the f-distribution used, and why is it approximate for these tests ?"
      ],
      "metadata": {
        "id": "WwuPH2AL_nZJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The F-distribution is used in various statistical tests primarily because it helps compare variances between groups. Here are the main types of tests:\n",
        "\n",
        "1.Analysis of Variance (ANOVA):\n",
        "   \n",
        "  (a).Purpose: To determine if there are significant differences between the means of three or more groups.\n",
        "\n",
        "(b).Why F-distribution?:\n",
        "\n",
        " It compares the variance between group means to the variance within groups. The F-distribution is appropriate here because it allows us to understand whether the observed group differences are greater than what could be expected due to random variation.\n",
        "\n",
        "\n",
        "2.Regression Analysis:\n",
        "\n",
        "(a).Purpose: To assess the overall significance of a regression model.\n",
        "\n",
        "(b).Why F-distribution?: It tests whether the relationship between the dependent variable and the set of independent variables is statistically significant. The F-distribution helps in comparing the explained variance by the model to the unexplained variance (residuals).\n",
        "\n",
        "3.Testing Equality of Variances (F-test):\n",
        "\n",
        "(a).Purpose: To compare the variances of two independent samples.\n",
        "\n",
        "(b).Why F-distribution?: By comparing the ratio of the two variances, the F-distribution allows us to determine if the variances are significantly different.\n",
        "\n",
        "The F-distribution's ability to handle comparisons of variances and its properties make it ideal for these types of statistical tests. It helps researchers make informed decisions about the significance and relationships within their data."
      ],
      "metadata": {
        "id": "haKPfFDXARdF"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w-gz7By0B7HN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.3.What are the key assumptions required for conducting an F-test to compare the variances of two\n",
        "populations?\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "XRerVCyhB_vh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For an F-test to be valid when comparing the variances of two populations, several key assumptions must be met:\n",
        "\n",
        "(a).Independence: The samples must be independent of each other. That is, the selection of one sample should not influence the selection of the other.\n",
        "\n",
        "(b).Normality: Both populations should be normally distributed. The F-test is sensitive to departures from normality.\n",
        "\n",
        "(c).Equal Sample Sizes (preferable but not mandatory): Ideally, both samples should have the same size, although the test can still be performed with unequal sample sizes.\n",
        "\n",
        "(d).Random Sampling: The data should be collected through random sampling from the populations.\n",
        "\n",
        "These assumptions ensure the F-test's results are reliable and accurately reflect the differences in variances between the two populations."
      ],
      "metadata": {
        "id": "HH583EjjCaOP"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_J-9Hg-4CD5a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " 4.What is the purpose of ANOVA, and how does it differ from a t-test?"
      ],
      "metadata": {
        "id": "vp0Icga1C9RU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Purpose of ANOVA (Analysis of Variance):\n",
        "\n",
        "(a).ANOVA is used to determine if there are statistically significant differences between the means of three or more independent groups. It's particularly useful when you want to compare multiple groups simultaneously without increasing the risk of Type I errors (false positives).\n",
        "\n",
        "(b).How it works: ANOVA compares the variance between the groups to the variance within the groups. If the between-group variance is significantly higher than the within-group variance, it indicates that at least one group mean is different from the others.\n",
        "\n",
        "\n",
        "#### t-test:\n",
        "Purpose: A t-test is used to compare the means of two groups to see if they are significantly different from each other.\n",
        "\n",
        "Types:\n",
        "\n",
        "Independent (two-sample) t-test: Compares the means of two independent groups.\n",
        "\n",
        "Paired (dependent) t-test: Compares the means of the same group at different times or under different conditions.\n",
        "\n",
        "#### Differences between ANOVA and t-test:\n",
        "\n",
        "Number of Groups:\n",
        "\n",
        "#### * t-test: Suitable for comparing the means of two groups.\n",
        "\n",
        "ANOVA: Ideal for comparing the means of three or more groups.\n",
        "\n",
        "#### Risk of Error:\n",
        "\n",
        "#### * t-test: Conducting multiple t-tests increases the risk of Type I errors.\n",
        "\n",
        "#### * ANOVA: Reduces the risk of Type I errors by allowing multiple group comparisons in one test.\n",
        "\n",
        "#### Analysis of Variance:\n",
        "\n",
        "* t-test: Focuses on the differences between the means of two groups.\n",
        "\n",
        "* ANOVA: Examines the variance within and between groups to determine if there are any significant differences among multiple group means.\n",
        "\n",
        "So, while both tests are used for hypothesis testing involving means, ANOVA is the go-to method when we need to compare more than two groups simultaneously."
      ],
      "metadata": {
        "id": "RY_e6npbDEDG"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gCWB4aliDDQP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.5. Explain when and why you would use a one-way ANOVA instead of multiple t-tests when comparing more than two groups."
      ],
      "metadata": {
        "id": "qygw1Psb8DDO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Choosing between a one-way ANOVA and multiple t-tests comes down to efficiency and the need to control the risk of Type I errors.\n",
        "\n",
        "### When to use a one-way ANOVA:\n",
        "\n",
        "* When comparing more than two groups: If we have three or more groups to compare, a one-way ANOVA is the appropriate choice.\n",
        "\n",
        "* ### To avoid increased Type I errors:\n",
        "Conducting multiple t-tests increases the risk of Type I errors. For example, if we have 4 groups and perform a t-test for every possible pair (6 tests in total), the likelihood of a false positive increases. ANOVA controls this by performing a single test to determine if there are any significant differences among the group means.\n",
        "\n",
        "* ### For overall group comparison:\n",
        "ANOVA tells us if there's a statistically significant difference among group means, but not specifically which groups differ. If ANOVA indicates a difference, we can follow up with post-hoc tests (like Tukey's HSD) to identify where those differences lie.\n",
        "\n",
        "### Why use a one-way ANOVA:\n",
        "* Efficiency: One-way ANOVA is designed for multi-group comparison in one step, saving time and computational resources.\n",
        "* Accuracy: It maintains a controlled level of error probability, ensuring more reliable results.\n",
        "*Interpretability: Provides a clear, overall picture of differences among multiple groups, without the complications and increased error risks of multiple tests.\n",
        "\n",
        "In essence, one-way ANOVA is the go-to method for comparing more than two groups to ensure our results are accurate, reliable, and efficient."
      ],
      "metadata": {
        "id": "V0JslMcU8M_X"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7xZb2m-C8L3A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.6.Explain how variance is partitioned in ANOVA into between-group variance and within-group variance.\n",
        "How does this partitioning contribute to the calculation of the F-statistic?"
      ],
      "metadata": {
        "id": "dcNaLAtK9qez"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variance Partitioning in ANOVA:\n",
        "\n",
        "(a).Total Variance: This is the overall variance in the dataset, considering all observations. It‚Äôs the sum of the variances due to the differences between the group means and the variances within each group.\n",
        "\n",
        "(b).Between-Group Variance (SSB - Sum of Squares Between): This measures how much the group means differ from the overall mean. It captures the variability due to the differences between the groups.\n",
        "\n",
        "$$\n",
        "SSB = \\sum_{i=1}^{k} n_i (\\overline{X}_i - \\overline{X})^2\n",
        "$$\n",
        "\n",
        "ùëã\n",
        "ùëñ\n",
        "ùëó\n",
        ": Individual observation in group i\n",
        "\n",
        "ùëã\n",
        "ùëñ\n",
        "Àâ\n",
        ": Mean of group i\n",
        "\n",
        "### Calculation of the F-statistic:\n",
        "The F-statistic is calculated by comparing the ratio of the between-group variance to the within-group variance. Here's how:\n",
        "\n",
        "(a). Mean Square Between (MSB):\n",
        "$$ ùëÄ\n",
        "ùëÜ\n",
        "ùêµ\n",
        "=\n",
        "ùëÜ\n",
        "ùëÜ\n",
        "ùêµ /\n",
        "ùëë\n",
        "ùëì\n",
        "ùëè $$\n",
        "\n",
        "ùëë\n",
        "ùëì\n",
        "ùëè\n",
        ": Degrees of freedom between groups =\n",
        "ùëò\n",
        "‚àí\n",
        "1\n",
        ", where k is the number of groups.\n",
        "\n",
        "\n",
        "(b).**Mean Square Within (MSW)**:\n",
        "$$\n",
        "MSW = \\frac{SSW}{df_w}\n",
        "$$\n",
        "\n",
        "- \\( df_w \\): Degrees of freedom within groups = \\( N - k \\), where \\( N \\) is the total number of observations and \\( k \\) is the number of groups.\n",
        "\n",
        "\n",
        "(c).F-statistic:\n",
        "F=ùëÄùëÜùêµ/ùëÄùëÜùëä\n",
        "\n",
        "If the between-group variance (MSB) is significantly larger than the within-group variance (MSW), the F-statistic will be large, indicating that there are significant differences between the group means. This helps us determine if at least one group mean is different from the others, allowing for more refined insights from our data."
      ],
      "metadata": {
        "id": "73moAZq99yAB"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fiVkDAUbCSe3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.7.Compare the classical (frequentist) approach to ANOVA with the Bayesian approach. What are the key differences in terms of how they handle uncertainty, parameter estimation, and hypothesis testing?"
      ],
      "metadata": {
        "id": "B5o2snE1CYw1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see these two approaches handle ANOVA, focusing on their differing philosophies and methodologies:\n",
        "\n",
        "### Classical (Frequentist) Approach\n",
        "Uncertainty:\n",
        "\n",
        "* Views probabilities as long-term frequencies. Uncertainty is expressed through confidence intervals and p-values.\n",
        "\n",
        "* Relies on the idea that with a large number of repeated samples, the true parameter will be captured by the confidence interval a certain percentage of the time (e.g., 95% confidence interval).\n",
        "\n",
        "### Parameter Estimation:\n",
        "* Parameters (e.g., mean, variance) are fixed but unknown quantities.\n",
        "* Uses point estimates like sample means and variances to estimate population parameters.\n",
        "* Confidence intervals provide a range of plausible values for these parameters\n",
        "\n",
        "### Hypothesis Testing:\n",
        "* Relies on p-values to test null hypotheses. A low p-value (typically < 0.05) leads to rejecting the null hypothesis.\n",
        "* Strict dichotomy: Either reject or fail to reject the null hypothesis based on pre-defined significance levels.\n",
        "\n",
        "### Bayesian Approach\n",
        "\n",
        "Bayesian Approach:\n",
        "* Views probabilities as degrees of belief or certainty about an event.\n",
        "* Uncertainty is handled through probability distributions. For instance, the parameters themselves are treated as random variables with their own distributions.\n",
        "\n",
        "Parameter Estimation:\n",
        "* Parameters are not fixed but are described by a probability distribution (the posterior distribution), which is updated with data using Bayes' theorem.\n",
        "* Combines prior information (beliefs before seeing the data) with the likelihood of the observed data to produce the posterior distribution.\n",
        "* This posterior distribution provides a full picture of uncertainty and allows for direct probabilistic statements (e.g., \"There is a 95% probability that the mean is between X and Y\").\n",
        "\n",
        "Hypothesis Testing:\n",
        "\n",
        "* Hypotheses are tested using the posterior distributions. Bayes factors compare the likelihood of the data under different hypotheses.\n",
        "* More flexible interpretation: Instead of a strict reject/accept decision, it provides a probability-based understanding of how much more likely one hypothesis is compared to another.\n",
        "\n",
        "Key Differences\n",
        "\n",
        "(a).Interpretation of Probability:\n",
        "* Frequentist: Probability as long-term frequency.\n",
        "*Bayesian: Probability as degree of belief.\n",
        "\n",
        "(b).Uncertainty and Estimation:\n",
        "* Frequentist: Fixed but unknown parameters, confidence intervals.\n",
        "* Bayesian: Parameters have distributions, posterior probabilities.\n",
        "\n",
        "(c).Hypothesis Testing:\n",
        "* Frequentist: P-values, reject/fail to reject framework.\n",
        "* Bayesian: Posterior probabilities, Bayes factors, more nuanced interpretation.\n",
        "\n",
        "(d).Use of Prior Information:\n",
        "* Frequentist: No explicit prior information used.\n",
        "* Bayesian: Incorporates prior beliefs or knowledge, updating with data.\n",
        "\n",
        "In summary, the classical approach is more rigid and straightforward, while the Bayesian approach is flexible, incorporates prior knowledge, and provides a probabilistic interpretation of parameters and hypotheses. Both have their strengths and appropriate use cases, and choosing between them often depends on the specific context and the nature of the data and questions at hand.\n"
      ],
      "metadata": {
        "id": "lGaXhzZDChYo"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sCyXgBSaFV9A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.8. Question: You have two sets of data representing the incomes of two different professions:\n",
        "* Profession A2 [48, 52, 55, 60, 62]\n",
        "* Profession B2 [45, 50, 55, 52, 47]  Perform an F-test to determine if the variances of the two professions'\n",
        "incomes are equal. What are your conclusions based on the F-test?\n",
        "\n",
        "Task:Use Python to calculate the F-statistic and p-value for the given data.\n",
        "\n",
        "Objective: Gain experience in performing F-tests and interpreting the results in terms of variance comparison.\n"
      ],
      "metadata": {
        "id": "g91gi3xIFmhL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Let's walk through the F-test using Python to determine if the variances of the two professions' incomes are equal."
      ],
      "metadata": {
        "id": "uamwaZ3QG_hv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "# Data\n",
        "Profession_A2 = [48, 52, 55, 60, 62]\n",
        "Profession_B2 = [45, 50, 55, 52, 47]\n",
        "\n",
        "# Step 2: Calculate variances\n",
        "var_A2 = np.var(Profession_A2, ddof=1)\n",
        "var_B2 = np.var(Profession_B2, ddof=1)\n",
        "\n",
        "# Step 3: Calculate the F-statistic\n",
        "F_statistic = var_A2 / var_B2\n",
        "print(f'F-statistic: {F_statistic}')\n",
        "\n",
        "# Step 4: Calculate the p-value\n",
        "df1 = len(Profession_A2) - 1\n",
        "df2 = len(Profession_B2) - 1\n",
        "p_value = stats.f.cdf(F_statistic, df1, df2)\n",
        "p_value = 2 * min(p_value, 1 - p_value)  # Two-tailed test\n",
        "print(f'p-value: {p_value}')\n",
        "\n",
        "# Interpretation\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis: The variances are significantly different.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: The variances are not significantly different.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6CMrnD5DHGhw",
        "outputId": "43280cb7-2612-40f5-aa08-b442bc284257"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F-statistic: 2.089171974522293\n",
            "p-value: 0.49304859900533904\n",
            "Fail to reject the null hypothesis: The variances are not significantly different.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "nUh7QN9aGkKU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Let's break down what's happening here:\n",
        "(a).Import necessary libraries: Using numpy for basic calculations and scipy for the F-test.\n",
        "\n",
        "(b).Calculate variances: Using np.var with ddof=1 for sample variance.\n",
        "\n",
        "(c).Calculate the F-statistic: By dividing the variance of Profession A2 by the variance of Profession B2.\n",
        "\n",
        "(d).Calculate the p-value: Using scipy.stats.f.cdf to get the cumulative distribution function value, then adjusting for a two-tailed test.\n",
        "\n",
        "(e).Interpret results: Comparing the p-value to the significance level (alpha).\n",
        "\n",
        "Running this code will give us the F-statistic and p-value, helping us conclude whether the variances of the two professions' incomes are equal or significantly different."
      ],
      "metadata": {
        "id": "5s2qSAxxHeM4"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pBtn6wDKIRjM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.9. Question:Conduct a one-way ANOVA to test whether there are any statistically significant differences in average heights between three different regions with the following data:\n",
        "* Region A2 [160, 162, 165, 158, 164]\n",
        "* Region B2 [172, 175, 170, 168, 174]\n",
        "* Region C2 [180, 182, 179, 185, 183]\n",
        "* Task2 Write Python code to perform the one-way ANOVA and interpret the results.\n",
        "* Objective: Learn how to perform one-way ANOVA using Python and interpret F-statistic and p-value."
      ],
      "metadata": {
        "id": "GIEB-loKIbEE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's perform a one-way ANOVA to test if there are statistically significant differences in average heights between the three regions."
      ],
      "metadata": {
        "id": "uPWxuBokKL82"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "6X-QtoCMKRuO"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Step 2: Create dataset\n",
        "# Data\n",
        "Region_A2 = [160, 162, 165, 158, 164]\n",
        "Region_B2 = [172, 175, 170, 168, 174]\n",
        "Region_C2 = [180, 182, 179, 185, 183]\n",
        "\n",
        "data = {\n",
        "    'Region A2': Region_A2,\n",
        "    'Region B2': Region_B2,\n",
        "    'Region C2': Region_C2\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "print(df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9h4qOsIqK1aR",
        "outputId": "3224bb63-645e-463b-e70a-30985afd6ad3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Region A2  Region B2  Region C2\n",
            "0        160        172        180\n",
            "1        162        175        182\n",
            "2        165        170        179\n",
            "3        158        168        185\n",
            "4        164        174        183\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Step 3: Perform the one-way ANOVA\n",
        "\n",
        "# Perform one-way ANOVA\n",
        "f_stat, p_value = stats.f_oneway(df['Region A2'], df['Region B2'], df['Region C2'])\n",
        "print(f'F-statistic: {f_stat}, p-value: {p_value}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6qUL6VCELKb8",
        "outputId": "1e2a2734-628a-4fe9-ce17-1c88b3de7b86"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F-statistic: 67.87330316742101, p-value: 2.870664187937026e-07\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Step 4: Interpret the results\n",
        "* F-statistic: This value measures the ratio of the variance between the groups to the variance within the groups.\n",
        "* p-value: If the p-value is less than the significance level (commonly 0.05), it indicates that there are statistically significant differences between the group means."
      ],
      "metadata": {
        "id": "GLoLXz9sLyTb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data\n",
        "Region_A2 = [160, 162, 165, 158, 164]\n",
        "Region_B2 = [172, 175, 170, 168, 174]\n",
        "Region_C2 = [180, 182, 179, 185, 183]\n",
        "\n",
        "data = {\n",
        "    'Region A2': Region_A2,\n",
        "    'Region B2': Region_B2,\n",
        "    'Region C2': Region_C2\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "print(df)\n",
        "\n",
        "# Perform one-way ANOVA\n",
        "f_stat, p_value = stats.f_oneway(df['Region A2'], df['Region B2'], df['Region C2'])\n",
        "print(f'F-statistic: {f_stat}, p-value: {p_value}')\n",
        "\n",
        "# Interpret the results\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis: There are significant differences between the group means.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: No significant difference between the group means.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7M-fhHirMCY6",
        "outputId": "4ef08708-d201-4d3b-983d-35f97440a3da"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Region A2  Region B2  Region C2\n",
            "0        160        172        180\n",
            "1        162        175        182\n",
            "2        165        170        179\n",
            "3        158        168        185\n",
            "4        164        174        183\n",
            "F-statistic: 67.87330316742101, p-value: 2.870664187937026e-07\n",
            "Reject the null hypothesis: There are significant differences between the group means.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Interpretation:\n",
        "\n",
        "* If the p-value is less than 0.05, you reject the null hypothesis, indicating significant differences in average heights between the regions.\n",
        "* If the p-value is greater than 0.05, you fail to reject the null hypothesis, indicating no significant differences in average heights between the regions."
      ],
      "metadata": {
        "id": "Re_XLxSmMJEu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "x0Nom6jSJw-q"
      }
    }
  ]
}